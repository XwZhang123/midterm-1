import os
import shutil
import time
import torch
import torchvision
from torchvision import datasets, transforms, models
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.models import ResNet18_Weights
from torch.utils.tensorboard import SummaryWriter

# 文件路径定义
path_images = r'C:\Users\23969\Desktop\CUB_200_2011\images.txt'
path_split = r'C:\Users\23969\Desktop\CUB_200_2011\train_test_split.txt'
path_images_folder = r'C:\Users\23969\Desktop\CUB_200_2011\images'
train_save_path = r'C:\Users\23969\Desktop\CUB_200_2011\dataset\train'
test_save_path = r'C:\Users\23969\Desktop\CUB_200_2011\dataset\test'

# 设置批处理大小
BATCH_SIZE = 16

# 图像预处理
data_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

def load_data(root, batch_size, num_workers=4, pin_memory=True):
    dataset = datasets.ImageFolder(root, transform=data_transform)
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)
    return dataset.class_to_idx, loader

# 加载训练和测试数据
train_class, train_loader = load_data(train_save_path, BATCH_SIZE)
test_class, test_loader = load_data(test_save_path, BATCH_SIZE)

def train_model(model, train_loader, criterion, optimizer, num_epochs=25, device='cpu', writer=None):
    model = model.to(device)
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        running_corrects = 0
        
        for inputs, labels in train_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            _, preds = torch.max(outputs, 1)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)
        
        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = running_corrects.double() / len(train_loader.dataset)
        
        if writer:
            writer.add_scalar('Loss/train', epoch_loss, epoch)
            writer.add_scalar('Accuracy/train', epoch_acc, epoch)
        
        print(f'Epoch {epoch}/{num_epochs - 1}')
        print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')
    
    return model

def test_model(model, test_loader, criterion, device='cpu', writer=None, epoch=None):
    model.eval()
    running_loss = 0.0
    running_corrects = 0
    
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)
            
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            _, preds = torch.max(outputs, 1)
            
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)
    
    loss = running_loss / len(test_loader.dataset)
    acc = running_corrects.double() / len(test_loader.dataset)
    
    if writer and epoch is not None:
        writer.add_scalar('Loss/test', loss, epoch)
        writer.add_scalar('Accuracy/test', acc, epoch)
    
    print(f'Test Loss: {loss:.4f} Acc: {acc:.4f}')
    
    return loss, acc

def experiment(num_epochs_list, lr_list, device='cpu'):
    results = []
    writer = SummaryWriter(log_dir='runs/cub200_experiment')
    
    for num_epochs in num_epochs_list:
        for lr in lr_list:
            print(f"Training with num_epochs={num_epochs} and lr={lr}")
            
            # 加载预训练的ResNet-18模型并修改最后的全连接层
            model = models.resnet18(weights=ResNet18_Weights.DEFAULT)
            num_ftrs = model.fc.in_features
            model.fc = nn.Linear(num_ftrs, 200)
            
            # 定义损失函数和优化器
            criterion = nn.CrossEntropyLoss()
            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)
            
            # 训练和测试模型
            trained_model = train_model(model, train_loader, criterion, optimizer, num_epochs=num_epochs, device=device, writer=writer)
            test_loss, test_acc = test_model(trained_model, test_loader, criterion, device=device, writer=writer, epoch=num_epochs)
            
            results.append((num_epochs, lr, test_loss, test_acc))
            print(f"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}")
    
    writer.close()
    return results

if __name__ == '__main__':
    # 定义不同的超参数组合
    num_epochs_list = [10, 15, 20]  # 例如 10, 20 和 30 个 epoch
    lr_list = [0.001, 0.01, 0.1]  # 例如 0.001, 0.01 和 0.1 的学习率
    
    # 运行实验并记录结果
    results = experiment(num_epochs_list, lr_list, device='cpu')

    # 输出结果
    for num_epochs, lr, test_loss, test_acc in results:
        print(f"Epochs: {num_epochs}, LR: {lr}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}")
   # 保存模型的权重
    save_dir = r'C:\Users\23969\Desktop\CUB_200_2011\model_weights'
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
